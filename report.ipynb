{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center><b>CSC14120 â€“ PARALLEL PROGRAMMING</b></h1>\n",
    "\n",
    "<h2 align=center>FINAL PROJECT</h2>\n",
    "<p style=\"font-size:32px;text-align:center\">Parallelize Convolutional Layer in the LeNet-5 Architecture using CUDA</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student information**\n",
    "\n",
    "Student name         | Student ID \n",
    "---------------------|-------------\n",
    "Nguyen Quang Gia Bao | 20120040\n",
    "Huynh Tuan Nam       | 20120136\n",
    "Tran Hoang Anh Phi   | 20120158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Table of Contents__\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "   1. [Objectives](#objectives)\n",
    "   2. [Dataset](#dataset)\n",
    "2. [Background](#background)\n",
    "   1. [Convolutional Neural Networks (CNNs)](#cnns)\n",
    "   2. [LeNet-5](#lenet-5)\n",
    "3. [Starter project](#starter)\n",
    "4. [Implementation](#implementation)\n",
    "   1. [Convolutional Layer](#convolutional-layer)\n",
    "   2. [Pooling Layer](#pooling-layer)\n",
    "   3. [Fully Connected Layer](#fully-connected-layer)\n",
    "   4. [LeNet-5 Architecture](#lenet-5-architecture)\n",
    "   5. [Parallelization](#parallelization)\n",
    "5. [Usage](#usage)\n",
    "   1. [Prerequisites](#prerequisites)\n",
    "   2. [Training](#training)\n",
    "   3. [Testing](#testing)\n",
    "6. [Results](#results)\n",
    "   1. [Training stage](#training-stage)\n",
    "   2. [Testing stage](#testing-stage)\n",
    "      1. [Basic kernel](#basic-kernel)\n",
    "      2. [Optimized kernel 1](#optimized-kernel-1)\n",
    "      3. [Optimized kernel 2](#optimized-kernel-2)\n",
    "      4. [Optimized kernel 3](#optimized-kernel-3)\n",
    "7. [Conclusion](#conclusion)\n",
    "8. [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1    Introduction <a id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1    Objectives <a id=\"objectives\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Objective__: Implement and optimize the forward-pass of a convolutional layer using CUDA. \n",
    "- Convolutional layers are the primary building blocks of convolutional neural networks (CNNs), which are used in many machine learning tasks.\n",
    "- In general, CNNs work well on tasks where the data/input features have some level of partial relationship.\n",
    "\n",
    "<center>\n",
    "\n",
    "![](https://www.datasciencecentral.com/wp-content/uploads/2021/10/1lvvWF48t7cyRWqct13eU0w.jpeg)\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2    Dataset <a id=\"dataset\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Fashion-MNIST__ is a dataset of Zalando's article images - consisting of a training set of 60,000 examples and a test set of 10,000 examples | Each example is a $28x28$ grayscale image, associated with 10 classes |  Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms | It shares the same image size and structure of training and testing splits | \n",
    "\n",
    "- Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n",
    "    - To locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix.\n",
    "    - For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.\n",
    "\n",
    "\n",
    "- __Labels__: Each training and test example is assigned to one of the following labels:\n",
    "<center>\n",
    "\n",
    "0 | T-shirt/top\n",
    "--|------------\n",
    "1 | Trouser\n",
    "2 | Pullover\n",
    "3 | Dress\n",
    "4 | Coat\n",
    "5 | Sandal\n",
    "6 | Shirt\n",
    "7 | Sneaker\n",
    "8 | Bag\n",
    "9 | Ankle boot\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Background <a id=\"background\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1    Convolutional Neural Networks (CNNs)<a id=\"cnns\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standford [cheatsheat](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks#overview)\n",
    "  \n",
    "- Video CNNs: [\"How Convolutional Neural Networks work\"](https://www.youtube.com/watch?v=FmpDIaiMIeA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2    LeNet-5 <a id=\"lenet-5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A Complete Guide: [here](https://www.kaggle.com/code/blurredmachine/lenet-architecture-a-complete-guide/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Starter project <a id=\"starter-project\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Implementation <a id=\"implementation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original starter project was used the Eigen library version 3.3.4, which is not compatible with CUDA. Therefore, we have to upgrade the Eigen library to version 3.4.0, which is compatible with CUDA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1    Convolutional layer<a id=\"convolutional-layer\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolution layer (CONV) uses filters that perform convolution operations as it is scanning the input $\\mathbb{I}$ with respect to its dimensions. Its hyperparameters include the filter size $\\mathbb{F}$ and stride $\\mathbb{S}$. The resulting output $\\mathbb{O}$ is called feature map or activation map.\n",
    "<center>\n",
    "\n",
    "![](https://stanford.edu/~shervine/teaching/cs-230/illustrations/architecture-cnn-en.jpeg?3b7fccd728e29dc619e1bd8022bf71cf)\n",
    "\n",
    "</center> \n",
    "\n",
    "The sequential implementation of the convolutional layer was use the im2col method to convert the input image into a matrix and then perform matrix multiplication with the filter matrix to get the output image. The im2col algorithm is a technique that converts an image into a matrix, such that each column of the matrix corresponds to a small patch of the image. This makes it easier to perform convolution operations using matrix multiplication, which can be faster and more efficient than looping over the image pixels. The im2col method is working as follows:\n",
    "- Convert input image of size O(HWC) to a patches matrix of size O(HW(K^2)C) \n",
    "- Convert filter into format __kernel height__ * __kernel width__ * __kernel channel__\n",
    "- Multiply the modified input and filter matrix using GEMM matrix multiplication to get the output. This is a single call.\n",
    "\n",
    "To illustrate the im2col algorithm with a greyscale example, let's assume we have a 4x4 image with one channel, and we want to apply a 2x2 filter with a stride of 1 and no padding. The im2col algorithm would produce a 4x9 matrix, where each column represents a 2x2 patch of the image, as shown below:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "a & b & c & d \\\\\n",
    "e & f & g & h \\\\\n",
    "i & j & k & l \\\\\n",
    "m & n & o & p \\\\\n",
    "\\end{bmatrix}\n",
    "\\rightarrow\n",
    "\\begin{bmatrix}\n",
    "a & b & c & e & f & g & i & j & k \\\\\n",
    "b & c & d & f & g & h & j & k & l \\\\\n",
    "e & f & g & i & j & k & m & n & o \\\\\n",
    "f & g & h & j & k & l & n & o & p \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now, we can multiply this matrix by a vectorized version of the filter, and reshape the result into a 3x3 output image. For example, if the filter is:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then the vectorized filter is:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "4 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "And the output image is:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "a + 2b + 3e + 4f & b + 2c + 3f + 4g & c + 2d + 3g + 4h \\\\\n",
    "e + 2f + 3i + 4j & f + 2g + 3j + 4k & g + 2h + 3k + 4l \\\\\n",
    "i + 2j + 3m + 4n & j + 2k + 3n + 4o & k + 2l + 3o + 4p \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This is equivalent to sliding the filter over the image and computing the dot product at each position, but it can be done more efficiently using matrix operations. \n",
    "\n",
    "Here is the pseudo code for the im2col method:\n",
    "\n",
    "```c++\n",
    "input[C][H][W];\n",
    "kernels[M][K][K][C];\n",
    "output[M][H][W];\n",
    "for h in 1 to H do\n",
    "    for w in 1 to W do\n",
    "        for o in 1 to M do\n",
    "            sum = 0;\n",
    "            for x in 1 to K do\n",
    "                for y in 1 to K do\n",
    "                    for i in 1 to C do\n",
    "                    sum += input[i][h+y][w+x] * kernels[o][x][y][i];\n",
    "         output[o][w][h] = sum;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2    Pooling layer<a id=\"pooling-layer\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pooling layer is a downsampling operation, typically applied after a convolution layer, which does some spatial invariance. There has been a lot of research on the pooling layer, and the most common pooling methods are max pooling and average pooling. In this project, we will implement both of them. \n",
    "<p align=\"center\">\n",
    "    <img src=\"https://www.mdpi.com/remotesensing/remotesensing-13-04712/article_deploy/html/images/remotesensing-13-04712-g005.png\" width=\"600\" height=\"400\">\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "\n",
    "Type | Max pooling | Average pooling\n",
    "-----|-------------|----------------\n",
    "Purpose | Each pooling operation selects the maximum value of the current view | Each pooling operation averages the values of the current view\n",
    "Illustration | ![](https://stanford.edu/~shervine/teaching/cs-230/illustrations/max-pooling-a.png?711b14799d07f9306864695e2713ae07) | ![](https://stanford.edu/~shervine/teaching/cs-230/illustrations/average-pooling-a.png?58f9ab6d61248c3ec8d526ef65763d2f)\n",
    "Comments | - Preserves detected features <br> - Most commonly used | - Downsamples features map <br> - Used in LeNet\n",
    "\n",
    "</center>\n",
    "\n",
    "In our implementation, max pooling was utilized. Max pooling is a pooling operation that selects the maximum element from the region of the feature map covered by the filter. Thus, the output after max pooling will be a feature map containing the most prominent features of the previous feature map. \n",
    "\n",
    "This code implements the forward pass of a max pooling operation. Max pooling is a common operation in convolutional neural networks (CNNs) used to reduce the spatial dimensions of an input feature map while retaining the most important information.\n",
    "\n",
    "Let's go through the workflow of this code step by step:\n",
    "```bash\n",
    "# Input:\n",
    "# bottom: Matrix object representing the input feature map\n",
    "# dim_out: Number of output channels\n",
    "# n_sample: Number of samples in the input feature map\n",
    "# hw_in: Total number of elements in the input feature map\n",
    "# hw_pool: Total number of elements in the pooling window\n",
    "# hw_out: Total number of elements in the output feature map\n",
    "\n",
    "# Output:\n",
    "# top: Matrix object representing the output feature map\n",
    "# max_idxs: Vector storing the indices of the maximum values in each pooling window for each sample\n",
    "\n",
    "# Initialize top matrix with dimensions dim_out x n_sample and set all elements to the lowest possible float value\n",
    "top = Matrix(dim_out, n_sample)\n",
    "top.fill(std::numeric_limits<float>::lowest())\n",
    "\n",
    "# Initialize max_idxs vector\n",
    "max_idxs = Vector()\n",
    "\n",
    "# Iterate over each sample in the input feature map\n",
    "for sample in range(n_sample):\n",
    "    # Retrieve the image vector for the current sample\n",
    "    image = bottom.get_sample(sample)\n",
    "    \n",
    "    # Iterate over each channel in the input feature map\n",
    "    for channel in range(dim_out):\n",
    "        # Iterate over each element in the output feature map\n",
    "        for i_out in range(hw_out):\n",
    "            # Calculate the row and column indices of the top-left corner of the pooling window\n",
    "            step_h = i_out // (hw_out // hw_pool)\n",
    "            step_w = i_out % (hw_out // hw_pool)\n",
    "            \n",
    "            # Calculate the start index of the pooling window in the input feature map\n",
    "            start_idx = channel * hw_in + step_h * hw_pool * hw_in + step_w * hw_pool\n",
    "            \n",
    "            # Iterate over each element in the pooling window\n",
    "            for i_pool in range(hw_pool):\n",
    "                # Check if the current element is out of range\n",
    "                if start_idx + i_pool >= hw_in:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate the pick index of the current element in the input feature map\n",
    "                pick_idx = start_idx + i_pool\n",
    "                \n",
    "                # Compare the value of the current element in the input feature map with the corresponding element in the output feature map\n",
    "                if image[pick_idx] > top[channel * hw_out + i_out, sample]:\n",
    "                    # Update the corresponding element in the output feature map\n",
    "                    top[channel * hw_out + i_out, sample] = image[pick_idx]\n",
    "                    \n",
    "                    # Store the pick index in the max_idxs vector\n",
    "                    max_idxs.push_back(pick_idx)\n",
    "\n",
    "```\n",
    "\n",
    "Because the pooling layer dont have any trainable parameters, the backward pass is very simple. We just need to propagate the gradient from the output feature map to the input feature map. \n",
    "\n",
    "In summary, this code performs max pooling by iterating over each sample, channel, and element in the output feature map. It calculates the pooling window's top-left corner index, checks if the window is within range, and updates the output feature map with the maximum value in each pooling window. The corresponding indices of the maximum values are stored in the `max_idxs` vector.\n",
    "\n",
    "In particular, max and average pooling are special kinds of pooling where the maximum and average value is taken, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3    Fully connected layer<a id=\"fully-connected-layer\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fully connected layer (FC) operates on a flatten input where each input is connected to all neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4    LeNet-5 architecture<a id=\"lenet-5-architecture\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the original LeNet-5 architecture, we will use a modified version of it. The original LeNet-5 architecture is shown below:\n",
    "![](https://d2l.ai/_images/lenet.svg)\n",
    "And the modified version is shown below:\n",
    "\n",
    "__First Layer: Convolutional Layer (CONV1):__\n",
    "\n",
    "- Parameters: Input (N) = 28, Padding (P) = 2, Filter (F) = 5 x 5, Stride (S) = 1\n",
    "- Conv Operation: ((N + 2P - F) / S) + 1 = ((28 + 4 - 5) / 1) + 1 = 28 x 28\n",
    "- We will apply 6 filters / kernels so we will get a 28 x 28 x 6 dimensional output\n",
    "\n",
    "__Second Layer: Max Pooling Layer (POOL1):__\n",
    "\n",
    "- Parameters: Input (N) = 28, Filter (F) = 2 x 2, Stride (S) = 2\n",
    "- AVG Pooling Operation: ((N + 2P -F) / S) + 1 = ((28 - 2) / 2) + 1 = 14 x 14\n",
    "- We will have a 14 x 14 x 6 dimensional output at the end of this pooling\n",
    "\n",
    "__Third Layer: Convolutional Layer (CONV2):__\n",
    "\n",
    "- Parameters: Input (N) = 14, Filter (F) = 5 x 5, Stride (S) = 1\n",
    "- Conv Operation: ((N + 2P - F) / S) + 1 = ((14 - 5) / 1) + 1 = 10 x 10\n",
    "- We will apply 16 filters / kernels so we will get a 10 x 10 x 16 dimensional output\n",
    "\n",
    "__Fourth Layer: Max Pooling Layer (POOL2):__\n",
    "\n",
    "- Parameters: Input (N) = 10, Filter (F) = 2 x 2, Stride (S) = 2\n",
    "- AVG Pooling Operation: ((N + 2P -F) / S) + 1 = ((10 - 2) / 2) + 1 = 5 x 5\n",
    "- We will have a 5 x 5 x 16 dimensional output at the end of this pooling\n",
    "\n",
    "__Fifth Layer: Fully Connected layer(FC1):__\n",
    "\n",
    "- Parameters: W: 400 * 120, b: 120\n",
    "- We will have an output of 120 x 1 dimension\n",
    "\n",
    "__Sixth Layer: Fully Connected layer(FC2):__\n",
    "\n",
    "- Parameters: W: 120 * 84, b: 84\n",
    "- We will have an output of 84 x 1 dimension\n",
    "\n",
    "__Seventh Layer: Output layer(Softmax):__\n",
    "\n",
    "- Parameters: W: 84 * 10, b: 10\n",
    "- We will get an output of 10 x 1 dimension\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=6, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Conv2D(filters=16, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5    Parallelize<a id=\"parallelize\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the teacher's instructions, we will only parallelize the __forward-pass__ of the convolutional layer using CUDA. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1    Basic kernel<a id=\"basic-kernel\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cuda-cpp\n",
    "__global__ void conv_forward_kernel(float *d_output, const float *d_input, const float *d_weight,\n",
    "                                    const int n_sample, const int channel_out, const int channel_in,\n",
    "                                    const int height_in, const int width_in, const int height_kernel)\n",
    "```\n",
    "This line defines a CUDA kernel function called `conv_forward_kernel`. It takes several input arguments, including pointers to `d_output`, `d_input`, and `d_weight` arrays, which represent the output, input, and weight tensors, respectively. The other arguments represent the dimensions of the tensors.\n",
    "\n",
    "```cuda-cpp\n",
    "const int height_out = height_in - height_kernel + 1;\n",
    "const int width_out = width_in - height_kernel + 1;\n",
    "```\n",
    "These two lines calculate the height and width of the output tensor based on the input tensor dimensions and the size of the convolutional kernel.\n",
    "\n",
    "```cuda-cpp\n",
    "#define y4d(i3, i2, i1, i0) d_output[(i3) * (channel_out * height_out * width_out) + (i2) * (height_out * width_out) + (i1) * (width_out) + i0]\n",
    "#define x4d(i3, i2, i1, i0) d_input[(i3) * (channel_in * height_in * width_in) + (i2) * (height_in * width_in) + (i1) * (width_in) + i0]\n",
    "#define k4d(i3, i2, i1, i0) d_weight[(i3) * (channel_in * height_kernel * height_kernel) + (i2) * (height_kernel * height_kernel) + (i1) * (height_kernel) + i0]\n",
    "```\n",
    "These lines define three macros: `y4d`, `x4d`, and `k4d`. These macros are used to access elements of the `d_output`, `d_input`, and `d_weight` arrays, respectively. They provide a convenient way to access elements in a 4-dimensional tensor using indices `i3`, `i2`, `i1`, and `i0`.\n",
    "\n",
    "```cuda-cpp\n",
    "int height_grid = ceil(1.0*height_out / TILE_WIDTH);\n",
    "int width_grid = ceil(1.0*width_out / TILE_WIDTH); \n",
    "```\n",
    "These two lines calculate the number of thread blocks needed to cover the height and width of the output tensor. The `TILE_WIDTH` is a constant that determines the size of each thread block.\n",
    "\n",
    "```cuda-cpp\n",
    "int b = blockIdx.x;                 // batch number\n",
    "int m = blockIdx.y;                 // output feature\n",
    "int h = (blockIdx.z / width_grid) * TILE_WIDTH + threadIdx.y; // row of the image matrix\n",
    "int w = (blockIdx.z % width_grid) * TILE_WIDTH + threadIdx.x; // col of the image matrix\n",
    "```\n",
    "These lines calculate the indices `b`, `m`, `h`, and `w` for the current thread. `blockIdx` represents the index of the current thread block, and `threadIdx` represents the index of the current thread within the block. These indices are used to determine the position of the current thread in the output tensor.\n",
    "\n",
    "```cuda-cpp\n",
    "float accum = 0.0f;\n",
    "```\n",
    "This line initializes a variable `accum` to store the accumulated sum of the convolution operation.\n",
    "\n",
    "```cuda-cpp\n",
    "if (h < height_out && w < width_out) \n",
    "{\n",
    "    for(int c=0; c<channel_in; c++)             // sum over all input features\n",
    "    {\n",
    "        for(int p=0; p<height_kernel; p++)         // KxK filter \n",
    "            for(int q=0; q<height_kernel; q++)\n",
    "                accum += x4d(b, c, h+p, w+q) * k4d(m, c, p, q); // 4 dimensions macro resolve thread index\n",
    "    }\n",
    "    y4d(b,m,h,w) = accum;\n",
    "} // endif (h < H_out && w < W_out)\n",
    "```\n",
    "This block of code performs the convolution operation. It checks if the current thread is within the valid range of the output tensor. If so, it iterates over the input channels (`channel_in`), the height and width of the convolutional kernel (`height_kernel`), and accumulates the product of the corresponding input and weight values into the `accum` variable. Finally, it stores the accumulated value in the output tensor using the `y4d` macro.\n",
    "\n",
    "```cuda-cpp\n",
    "#undef y4d\n",
    "#undef x4d\n",
    "#undef k4d\n",
    "```\n",
    "These lines undefine the previously defined macros to avoid any potential conflicts with other parts of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6    Save and load model<a id=\"save-load\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the model, we need to save and load the weights of the model. We implemented the `save_parameters` and `load_parameters` methods in the `Network` class to save and load the weights of the model with binary files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Usage <a id=\"usage\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Prerequisites <a id=\"prerequisites\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download and unzip [FASHION-MNIST](https://www.kaggle.com/datasets/zalando-research/fashionmnist) dataset in `mini-dnn-cpp/data/fashion-mnist/`.\n",
    "\n",
    "- Download and unzip [Eigen 3.4.0](https://gitlab.com/libeigen/eigen/-/releases/3.4.0), then place folder __Eigen__ in `mini-dnn-cpp/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Training <a id=\"training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make setup\n",
    "!make train\n",
    "!make train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Testing <a id=\"testing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the following command after each test to clean up the temporary files:\n",
    "\n",
    "```bash\n",
    "make clean\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Basic kernel <a id=\"basic-kernel\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make your changes take effect please reactivate your environment\n",
      "rm -f src/layer/*.o\n",
      "rm test.o\n",
      "rm test\n",
      "To make your changes take effect please reactivate your environment\n",
      "make network.o\n",
      "make[1]: Entering directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "nvcc --compile src/network.cc -o src/network.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "make[1]: Leaving directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "make mnist.o\n",
      "make[1]: Entering directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "nvcc --compile src/mnist.cc -o src/mnist.o  -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "make[1]: Leaving directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "make layer\n",
      "make[1]: Entering directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "nvcc --compile src/layer/ave_pooling.cc -o src/layer/ave_pooling.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/conv.cc -o src/layer/conv.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/conv_gpu.cc -o src/layer/conv_gpu.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/fully_connected.cc -o src/layer/fully_connected.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/max_pooling.cc -o src/layer/max_pooling.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/relu.cc -o src/layer/relu.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/sigmoid.cc -o src/layer/sigmoid.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/softmax.cc -o src/layer/softmax.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "make[1]: Leaving directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "make loss\n",
      "make[1]: Entering directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "nvcc --compile src/loss/cross_entropy_loss.cc -o src/loss/cross_entropy_loss.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/loss/mse_loss.cc -o src/loss/mse_loss.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "make[1]: Leaving directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "make optimizer\n",
      "make[1]: Entering directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "nvcc --compile src/optimizer/sgd.cc -o src/optimizer/sgd.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "make[1]: Leaving directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "To make your changes take effect please reactivate your environment\n",
      "nvcc --compile src/layer/gpu/utils.cu -o src/layer/utils.o -I./ -L/usr/local/cuda/lib64 -lcudart \n",
      "nvcc --compile src/layer/gpu/conv_kernel.cu -o src/layer/conv_kernel.o -I./ -L/usr/local/cuda/lib64 -lcudart \n",
      "To make your changes take effect please reactivate your environment\n",
      "nvcc --compile test.cc -o test.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/network.cc -o src/network.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/mnist.cc -o src/mnist.o  -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/ave_pooling.cc -o src/layer/ave_pooling.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/conv.cc -o src/layer/conv.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/conv_gpu.cc -o src/layer/conv_gpu.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/fully_connected.cc -o src/layer/fully_connected.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/max_pooling.cc -o src/layer/max_pooling.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/relu.cc -o src/layer/relu.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/sigmoid.cc -o src/layer/sigmoid.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/softmax.cc -o src/layer/softmax.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/loss/cross_entropy_loss.cc -o src/loss/cross_entropy_loss.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/loss/mse_loss.cc -o src/loss/mse_loss.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/optimizer/sgd.cc -o src/optimizer/sgd.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc -o test -lm -lcuda -lrt test.o src/network.o src/mnist.o src/layer/*.o src/loss/*.o src/optimizer/*.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "To make your changes take effect please reactivate your environment\n",
      "nvcc --compile src/network.cc -o src/network.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/mnist.cc -o src/mnist.o  -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/ave_pooling.cc -o src/layer/ave_pooling.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/conv.cc -o src/layer/conv.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/conv_gpu.cc -o src/layer/conv_gpu.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/fully_connected.cc -o src/layer/fully_connected.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/max_pooling.cc -o src/layer/max_pooling.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/relu.cc -o src/layer/relu.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/sigmoid.cc -o src/layer/sigmoid.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/softmax.cc -o src/layer/softmax.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/loss/cross_entropy_loss.cc -o src/loss/cross_entropy_loss.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/loss/mse_loss.cc -o src/loss/mse_loss.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/optimizer/sgd.cc -o src/optimizer/sgd.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc -o test -lm -lcuda -lrt test.o src/network.o src/mnist.o src/layer/*.o src/loss/*.o src/optimizer/*.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "./test\n",
      "**********GPU info**********\n",
      "Name: NVIDIA RTX A6000\n",
      "Compute capability: 8.6\n",
      "Num SMs: 84\n",
      "Max num threads per SM: 1536\n",
      "Max num warps per SM: 48\n",
      "GMEM: 51050250240 byte\n",
      "SMEM per SM: 102400 byte\n",
      "SMEM per block: 49152 byte\n",
      "****************************\n",
      "mnist train number: 60000\n",
      "mnist test number: 10000\n",
      "Num Layers: 12\n",
      "Convolution c1 - GPU. Not Optimize:\n",
      "\t - Kernel Time: 1.37126 ms\n",
      "\t - Layer Time: 73.3622 ms\n",
      "Convolution c3 - GPU. Not Optimize:\n",
      "\t - Kernel Time: 3.58912 ms\n",
      "\t - Layer Time: 34.251 ms\n",
      "\n",
      "Test accuraccy on GPU: 0.8619\n"
     ]
    }
   ],
   "source": [
    "!make clean\n",
    "!make setup\n",
    "!make gpu_basic\n",
    "!make test\n",
    "!make run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Optimized kernel 1 <a id=\"optimize-kernel-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make your changes take effect please reactivate your environment\n",
      "rm -f src/layer/*.o\n",
      "rm test.o\n",
      "rm test\n",
      "To make your changes take effect please reactivate your environment\n",
      "make network.o\n",
      "make[1]: Entering directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "nvcc --compile src/network.cc -o src/network.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "make[1]: Leaving directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "make mnist.o\n",
      "make[1]: Entering directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "nvcc --compile src/mnist.cc -o src/mnist.o  -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "make[1]: Leaving directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "make layer\n",
      "make[1]: Entering directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "nvcc --compile src/layer/ave_pooling.cc -o src/layer/ave_pooling.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/conv.cc -o src/layer/conv.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/conv_gpu.cc -o src/layer/conv_gpu.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/fully_connected.cc -o src/layer/fully_connected.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/max_pooling.cc -o src/layer/max_pooling.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/relu.cc -o src/layer/relu.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/sigmoid.cc -o src/layer/sigmoid.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/softmax.cc -o src/layer/softmax.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "make[1]: Leaving directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "make loss\n",
      "make[1]: Entering directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "nvcc --compile src/loss/cross_entropy_loss.cc -o src/loss/cross_entropy_loss.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/loss/mse_loss.cc -o src/loss/mse_loss.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "make[1]: Leaving directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "make optimizer\n",
      "make[1]: Entering directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "nvcc --compile src/optimizer/sgd.cc -o src/optimizer/sgd.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "make[1]: Leaving directory '/mnt/net/i2x256-ai03/hotel/phit/personal/ParallelProgramming/mini-dnn-cpp'\n",
      "To make your changes take effect please reactivate your environment\n",
      "nvcc --compile src/layer/gpu/utils.cu -o src/layer/utils.o -I./ -L/usr/local/cuda/lib64 -lcudart \n",
      "nvcc --compile src/layer/gpu/conv_kernel1.cu -o src/layer/conv_kernel1.o -I./ -L/usr/local/cuda/lib64 -lcudart  \n",
      "To make your changes take effect please reactivate your environment\n",
      "nvcc --compile test.cc -o test.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/network.cc -o src/network.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/mnist.cc -o src/mnist.o  -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/ave_pooling.cc -o src/layer/ave_pooling.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/conv.cc -o src/layer/conv.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/conv_gpu.cc -o src/layer/conv_gpu.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/fully_connected.cc -o src/layer/fully_connected.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/max_pooling.cc -o src/layer/max_pooling.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/relu.cc -o src/layer/relu.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/sigmoid.cc -o src/layer/sigmoid.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/softmax.cc -o src/layer/softmax.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/loss/cross_entropy_loss.cc -o src/loss/cross_entropy_loss.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/loss/mse_loss.cc -o src/loss/mse_loss.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/optimizer/sgd.cc -o src/optimizer/sgd.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc -o test -lm -lcuda -lrt test.o src/network.o src/mnist.o src/layer/*.o src/loss/*.o src/optimizer/*.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "To make your changes take effect please reactivate your environment\n",
      "nvcc --compile src/network.cc -o src/network.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/mnist.cc -o src/mnist.o  -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/ave_pooling.cc -o src/layer/ave_pooling.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/conv.cc -o src/layer/conv.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/conv_gpu.cc -o src/layer/conv_gpu.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/fully_connected.cc -o src/layer/fully_connected.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/max_pooling.cc -o src/layer/max_pooling.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/relu.cc -o src/layer/relu.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/sigmoid.cc -o src/layer/sigmoid.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/layer/softmax.cc -o src/layer/softmax.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/loss/cross_entropy_loss.cc -o src/loss/cross_entropy_loss.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/loss/mse_loss.cc -o src/loss/mse_loss.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc --compile src/optimizer/sgd.cc -o src/optimizer/sgd.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "nvcc -o test -lm -lcuda -lrt test.o src/network.o src/mnist.o src/layer/*.o src/loss/*.o src/optimizer/*.o -I./ -L/usr/local/cuda/lib64 -lcudart\n",
      "./test\n",
      "**********GPU info**********\n",
      "Name: NVIDIA RTX A6000\n",
      "Compute capability: 8.6\n",
      "Num SMs: 84\n",
      "Max num threads per SM: 1536\n",
      "Max num warps per SM: 48\n",
      "GMEM: 51050250240 byte\n",
      "SMEM per SM: 102400 byte\n",
      "SMEM per block: 49152 byte\n",
      "****************************\n",
      "mnist train number: 60000\n",
      "mnist test number: 10000\n",
      "Num Layers: 12\n",
      "Convolution c1 - GPU. Optimize ver 1:\n",
      "\t - Kernel Time: 1.08755 ms\n",
      "\t - Layer Time: 74.6575 ms\n",
      "Convolution c3 - GPU. Optimize ver 1:\n",
      "\t - Kernel Time: 2.17805 ms\n",
      "\t - Layer Time: 32.2866 ms\n",
      "\n",
      "Test accuraccy on GPU: 0.2936\n"
     ]
    }
   ],
   "source": [
    "!make clean\n",
    "!make setup\n",
    "!make gpu_v1\n",
    "!make test\n",
    "!make run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 Optimized kernel 2 <a id=\"optimized-kernel-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make clean\n",
    "!make setup\n",
    "!make gpu_v2\n",
    "!make test\n",
    "!make run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.4 Optimized kernel 3 <a id=\"optimized-kernel-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make clean\n",
    "!make setup\n",
    "!make gpu_v3\n",
    "!make test\n",
    "!make run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Results <a id=\"results\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c++\n",
    "  Network dnn;\n",
    "  Layer *conv1 = new Conv(1, 28, 28, 6, 5, 5);\n",
    "  Layer *pool1 = new MaxPooling(6, 24, 24, 2, 2, 2);\n",
    "  Layer *conv2 = new Conv(6, 12, 12, 16, 5, 5);\n",
    "  Layer *pool2 = new MaxPooling(16, 8, 8, 2, 2, 2);\n",
    "  Layer* fc3 = new FullyConnected(pool2->output_dim(), 120);\n",
    "  Layer* fc4 = new FullyConnected(120, 84);\n",
    "  Layer* fc5 = new FullyConnected(84, 10);\n",
    "\n",
    "  Layer* relu1 = new ReLU;\n",
    "  Layer* relu2 = new ReLU;\n",
    "  Layer* relu3 = new ReLU;\n",
    "  Layer* relu4 = new ReLU;\n",
    "  Layer* relu5 = new ReLU;\n",
    "  Layer* softmax = new Softmax;\n",
    "  dnn.add_layer(conv1);\n",
    "  dnn.add_layer(relu1);\n",
    "  dnn.add_layer(pool1);\n",
    "  dnn.add_layer(conv2);\n",
    "  dnn.add_layer(relu2);\n",
    "  dnn.add_layer(pool2);\n",
    "  dnn.add_layer(fc3);\n",
    "  dnn.add_layer(relu3);\n",
    "  dnn.add_layer(fc4);\n",
    "  dnn.add_layer(relu4);\n",
    "  dnn.add_layer(fc5);\n",
    "  // dnn.add_layer(relu5);\n",
    "  dnn.add_layer(softmax);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default hyperparameters:\n",
    "\n",
    "```c++\n",
    "  int batch_size = 128;\n",
    "  float learning_rate = 0.001;\n",
    "```\n",
    "\n",
    "1. Train on Fashion-MNIST with 10 epochs\n",
    "```\n",
    "weight-bad-1.bin\n",
    "10-th epoch, test acc: 0.6136\n",
    "```\n",
    "\n",
    "2. Train on Fashion-MNIST with 10 epochs (dont use Relu activation at the (n - 1) layer (before softmax layer))\n",
    "```\n",
    "weight-1.bin\n",
    "10-th epoch, test acc: 0.8619\n",
    "```\n",
    "\n",
    "\n",
    "3. Train on Fashion-MNIST with 10 epochs with kernel size = 2\n",
    "```\n",
    "weight-bad-2.bin\n",
    "10-th epoch, test acc: 0.625\n",
    "```\n",
    "\n",
    "4. Train on Fashion-MNIST with 10 epochs with kernel size = 2 and dont use Relu at the penultimate layer\n",
    "```\n",
    "weight-2.bin\n",
    "10-th epoch, test acc: 0.8766\n",
    "```  \n",
    "\n",
    "5. Train on Fashion-MNIST with 15 epochs with kernel size = 2 and dont use Relu at the penultimate layer\n",
    "```\n",
    "weight-3.bin\n",
    "15-th epoch, test acc: 0.8862\n",
    "```\n",
    "\n",
    "6. Train on Fashion-MNIST with 20 epochs with kernel size = 2, lr=0.0005 and dont use Relu at the penultimate layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. References <a id=\"references\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.kaggle.com/datasets/zalando-research/fashionmnist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zalo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
